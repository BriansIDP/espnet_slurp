# network architecture
# encoder related
etype: vggblstmp     # encoder architecture type
elayers: 4
eunits: 1024
eprojs: 2048
subsample: "1_1_1_1" # skip every n frame from input to nth layers
# decoder related
dlayers: 1
dunits: 1024
# attention related
atype: location
adim: 1024
awin: 5
aheads: 4
aconv-chans: 10
aconv-filts: 100

# hybrid CTC/attention
mtlalpha: 0.0

# label smoothing
lsm-type: unigram
lsm-weight: 0.1

# minibatch related
batch-size: 15
maxlen-in: 800  # if input length  > maxlen_in, batchsize is automatically reduced
maxlen-out: 150 # if output length > maxlen_out, batchsize is automatically reduced
maxioratio: 300
minioratio: 6

# optimization related
sortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs
opt: adadelta
epochs: 100
patience: 0
accum-grad: 6
eps: 5e-9
# eps-decay: 1.0
weight-noise-std: 0.025
weight-noise-start: 30000

# scheduled sampling option
sampling-probability: 0.0

# Extra
dropout-rate: 0.0
dropout-rate-decoder: 0.1
weight-decay: 0.0001
context-residual: true
# report-interval-iters: 1

# KB related
meetingpath: /home/gs534/rds/hpc-work/work/Librispeech/KBs/LibriKB500_unigram600suffix
meetingKB: true
dictfile: /home/gs534/rds/hpc-work/work/Librispeech/KBs/bpe_dict_unigram600suffix.txt
lm-odim: 512
KBlextree: true
PtrGen: true
PtrSche: 0
init-full-model: /home/gs534/rds/hpc-work/work/Librispeech/exp/init_models/baseline.ep.20
# init-full-model: /home/dawna/gs534/espnet/egs/librispeech/debug/exp/librispeech_train_baseline_spec/results/model.acc.best
acousticonly: true
attn_dim: 256
# smoothprob: 0.6
# dynamicKBs: 9
